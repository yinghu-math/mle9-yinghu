{"cells":[{"cell_type":"markdown","source":["<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n     width=\"200px\"\n     height=\"auto\"/>\n</p>"],"metadata":{"id":"lmil5P4G6052","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f744bcdd-a74a-4ef1-acf6-6deba2d85188"}}},{"cell_type":"markdown","source":["# <h1 align=\"center\" id=\"heading\">Subscription Prediction with Delat Lake, PySpark, and MLlib</h1>"],"metadata":{"id":"oQU8pT9m6055","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f25fead1-c5a9-4222-a41c-5d1634dd3446"}}},{"cell_type":"markdown","source":["# Spark Environment\n\nMake sure that you open this notebook in your Spark environment!"],"metadata":{"id":"vxs4CnZ8MYR9","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa53c8e9-a0bb-46ec-8ce0-6e24a2734a98"}}},{"cell_type":"code","source":["# !pip install -U -q pyspark delta-spark # If you use Colab uncomment this line"],"metadata":{"id":"i5lvRImyZQKy","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bbb8ab6-9d3f-4d56-9d79-98d330f75b8e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Learning Objectives"],"metadata":{"id":"B30ILkiC6056","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d30ad23-2c5d-4f78-813f-56ef92c1d599"}}},{"cell_type":"markdown","source":["At the end of this session, you will be able to \n\n- Load, save, partition data with Delta Lake tables\n- Explore data with Spark DataFrames \n- Build a pipeline in MLlib for machine learning workflow\n- Fit a logistic regression model, make predictions, and evaluate the model"],"metadata":{"id":"Dvbp4ifI6057","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af99425d-297b-45de-8ba8-06104b351ea1"}}},{"cell_type":"markdown","source":["## Part 1: Data Loader\n\nWe are using a dataset from the UCI Machine Learning Repository.\n\n1. Use `wget` to download the dataset. Then use `ls` to verify that the `bank.zip` file is downloaded."],"metadata":{"id":"tTvh8EkV6057","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2571c03a-cae9-4b9b-9861-f040eb696b2a"}}},{"cell_type":"code","source":["%%sh\nwget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0Su1lUX6058","outputId":"dcf3d53c-06ad-44d6-db86-5c47bd11420e","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47992c5c-64ed-4402-91bb-4a465420fd9a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"--2022-09-15 23:48:10--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 579043 (565K) [application/x-httpd-php]\nSaving to: ‚Äòbank.zip‚Äô\n\n     0K .......... .......... .......... .......... ..........  8%  863K 1s\n    50K .......... .......... .......... .......... .......... 17% 1.71M 0s\n   100K .......... .......... .......... .......... .......... 26%  891K 0s\n   150K .......... .......... .......... .......... .......... 35% 1.74M 0s\n   200K .......... .......... .......... .......... .......... 44% 36.4M 0s\n   250K .......... .......... .......... .......... .......... 53% 71.3M 0s\n   300K .......... .......... .......... .......... .......... 61% 1.81M 0s\n   350K .......... .......... .......... .......... .......... 70% 24.8M 0s\n   400K .......... .......... .......... .......... .......... 79% 22.5M 0s\n   450K .......... .......... .......... .......... .......... 88% 25.8M 0s\n   500K .......... .......... .......... .......... .......... 97% 2.22M 0s\n   550K .......... .....                                      100% 24.0M=0.2s\n\n2022-09-15 23:48:10 (2.42 MB/s) - ‚Äòbank.zip‚Äô saved [579043/579043]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["--2022-09-15 23:48:10--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 579043 (565K) [application/x-httpd-php]\nSaving to: ‚Äòbank.zip‚Äô\n\n     0K .......... .......... .......... .......... ..........  8%  863K 1s\n    50K .......... .......... .......... .......... .......... 17% 1.71M 0s\n   100K .......... .......... .......... .......... .......... 26%  891K 0s\n   150K .......... .......... .......... .......... .......... 35% 1.74M 0s\n   200K .......... .......... .......... .......... .......... 44% 36.4M 0s\n   250K .......... .......... .......... .......... .......... 53% 71.3M 0s\n   300K .......... .......... .......... .......... .......... 61% 1.81M 0s\n   350K .......... .......... .......... .......... .......... 70% 24.8M 0s\n   400K .......... .......... .......... .......... .......... 79% 22.5M 0s\n   450K .......... .......... .......... .......... .......... 88% 25.8M 0s\n   500K .......... .......... .......... .......... .......... 97% 2.22M 0s\n   550K .......... .....                                      100% 24.0M=0.2s\n\n2022-09-15 23:48:10 (2.42 MB/s) - ‚Äòbank.zip‚Äô saved [579043/579043]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gAxRiyy605-","outputId":"9023a057-930e-458c-dd8e-2493d8bc8120","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14241a78-c5ad-4962-9322-e0e6bdf3737f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\u001B[0m\u001B[01;34mazure\u001B[0m/    \u001B[01;34meventlogs\u001B[0m/                   \u001B[01;34mlogs\u001B[0m/\r\nbank.zip  \u001B[01;34mganglia\u001B[0m/                     \u001B[01;34mmetastore_db\u001B[0m/\r\n\u001B[01;34mconf\u001B[0m/     \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*  \u001B[01;32mpreload_class.lst\u001B[0m*\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0m\u001B[01;34mazure\u001B[0m/    \u001B[01;34meventlogs\u001B[0m/                   \u001B[01;34mlogs\u001B[0m/\r\nbank.zip  \u001B[01;34mganglia\u001B[0m/                     \u001B[01;34mmetastore_db\u001B[0m/\r\n\u001B[01;34mconf\u001B[0m/     \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*  \u001B[01;32mpreload_class.lst\u001B[0m*\r\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["1. Unzip the file and use `ls` to see the files."],"metadata":{"id":"cGBxoptx605-","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"105f6433-edbb-4f68-9fde-3d162550224a"}}},{"cell_type":"code","source":["%%sh\nunzip bank.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hySwTxHs605_","outputId":"f9ac5ddd-807a-49e0-ca45-bc00e3bb8ac6","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"000511fa-ff85-406c-9186-34c56a0369a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Archive:  bank.zip\n  inflating: bank-full.csv           \n  inflating: bank-names.txt          \n  inflating: bank.csv                \n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Archive:  bank.zip\n  inflating: bank-full.csv           \n  inflating: bank-names.txt          \n  inflating: bank.csv                \n"]}}],"execution_count":0},{"cell_type":"code","source":["ls -lh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6UDQW1y605_","outputId":"4a312342-54ef-4722-98b0-38005bbcd06f","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2349ba91-fc61-456f-96bf-5f5aea6b32d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"total 6.7M\r\ndrwxr-xr-x 2 root root 4.0K Jan  1  1970 \u001B[0m\u001B[01;34mazure\u001B[0m/\r\n-rw-r--r-- 1 root root 4.4M Feb 14  2012 bank-full.csv\r\n-rw-r--r-- 1 root root 3.8K Feb 14  2012 bank-names.txt\r\n-rw-r--r-- 1 root root 451K Feb 14  2012 bank.csv\r\n-rw-r--r-- 1 root root 566K Feb 14  2012 bank.zip\r\ndrwxr-xr-x 2 root root 4.0K Jan  1  1970 \u001B[01;34mconf\u001B[0m/\r\ndrwxr-xr-x 3 root root 4.0K Sep 15 23:43 \u001B[01;34meventlogs\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 15 23:45 \u001B[01;34mganglia\u001B[0m/\r\n-r-xr-xr-x 1 root root 3.0K Jan  1  1970 \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*\r\ndrwxr-xr-x 2 root root 4.0K Sep 15 23:43 \u001B[01;34mlogs\u001B[0m/\r\ndrwxr-xr-x 5 root root 4.0K Sep 15 23:46 \u001B[01;34mmetastore_db\u001B[0m/\r\n-r-xr-xr-x 1 root root 1.3M Jan  1  1970 \u001B[01;32mpreload_class.lst\u001B[0m*\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["total 6.7M\r\ndrwxr-xr-x 2 root root 4.0K Jan  1  1970 \u001B[0m\u001B[01;34mazure\u001B[0m/\r\n-rw-r--r-- 1 root root 4.4M Feb 14  2012 bank-full.csv\r\n-rw-r--r-- 1 root root 3.8K Feb 14  2012 bank-names.txt\r\n-rw-r--r-- 1 root root 451K Feb 14  2012 bank.csv\r\n-rw-r--r-- 1 root root 566K Feb 14  2012 bank.zip\r\ndrwxr-xr-x 2 root root 4.0K Jan  1  1970 \u001B[01;34mconf\u001B[0m/\r\ndrwxr-xr-x 3 root root 4.0K Sep 15 23:43 \u001B[01;34meventlogs\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 15 23:45 \u001B[01;34mganglia\u001B[0m/\r\n-r-xr-xr-x 1 root root 3.0K Jan  1  1970 \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*\r\ndrwxr-xr-x 2 root root 4.0K Sep 15 23:43 \u001B[01;34mlogs\u001B[0m/\r\ndrwxr-xr-x 5 root root 4.0K Sep 15 23:46 \u001B[01;34mmetastore_db\u001B[0m/\r\n-r-xr-xr-x 1 root root 1.3M Jan  1  1970 \u001B[01;32mpreload_class.lst\u001B[0m*\r\n"]}}],"execution_count":0},{"cell_type":"code","source":["%%sh\nwc -l bank.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsKTEA_kJm1Z","outputId":"cc90db82-213d-4362-c8c2-38ab9373abbf","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2184acb1-67be-4369-bd79-1d8259790fc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"4522 bank.csv\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["4522 bank.csv\n"]}}],"execution_count":0},{"cell_type":"code","source":["%%sh\nhead bank.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUOdYkMKRrFf","outputId":"61dd1ff6-8d43-4e2a-f04f-94b6bc3da874","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74cf19db-31cc-4913-8ec7-76a0d2ccec70"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"\n33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"\n30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"\n59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failure\";\"no\"\n36;\"self-employed\";\"married\";\"tertiary\";\"no\";307;\"yes\";\"no\";\"cellular\";14;\"may\";341;1;330;2;\"other\";\"no\"\n39;\"technician\";\"married\";\"secondary\";\"no\";147;\"yes\";\"no\";\"cellular\";6;\"may\";151;2;-1;0;\"unknown\";\"no\"\n41;\"entrepreneur\";\"married\";\"tertiary\";\"no\";221;\"yes\";\"no\";\"unknown\";14;\"may\";57;2;-1;0;\"unknown\";\"no\"\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"\n33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"\n30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"\n59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failure\";\"no\"\n36;\"self-employed\";\"married\";\"tertiary\";\"no\";307;\"yes\";\"no\";\"cellular\";14;\"may\";341;1;330;2;\"other\";\"no\"\n39;\"technician\";\"married\";\"secondary\";\"no\";147;\"yes\";\"no\";\"cellular\";6;\"may\";151;2;-1;0;\"unknown\";\"no\"\n41;\"entrepreneur\";\"married\";\"tertiary\";\"no\";221;\"yes\";\"no\";\"unknown\";14;\"may\";57;2;-1;0;\"unknown\";\"no\"\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["1. Create a Delta table for `bank.csv` (Why Delta Lake? Here's a read [here](https://medium.com/@databeans-blogs/delta-lake-the-data-engineers-missing-piece-part-1-ebab66a3f8c0?source) from a data engineer's perspective)\n\n    We first set up a Python project `ml-bank`, configure the SparkSession with the `configure_spark_with_delta_pip()` utility function in Delta Lake:"],"metadata":{"id":"1CLp_YaaNRvB","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b101fdfe-3402-4769-ab7b-7581168ab308"}}},{"cell_type":"code","source":["import pyspark\nfrom delta import *\n\nbuilder = pyspark.sql.SparkSession.builder.appName(\"ml-bank\") \\\n  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n\nspark = configure_spark_with_delta_pip(builder).getOrCreate()"],"metadata":{"id":"2VvPSH-2DVMy","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"035d16c3-4eac-4220-b635-721aa0f4f0da"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We define output formats and paths, you need to complete code to load the data from its source (since the delimiter of the file is semicolon, use [`spark.read.csv`](https://spark.apache.org/docs/latest/sql-data-sources-csv.html) that provides more flexibility) and write the data to its target (hint: [Create a table](https://docs.databricks.com/delta/quick-start.html#create-a-table))."],"metadata":{"id":"NaHADc7XPgTA","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d11d9e0-0b80-4543-9b64-829c7a6a1871"}}},{"cell_type":"code","source":["%%sh\npwd"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d31e86d9-6c92-4f2f-a8ae-5b333eec5015"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/driver\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/driver\n"]}}],"execution_count":0},{"cell_type":"code","source":["ls"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"282e4921-8583-41d6-beef-69ee5bd426ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\u001B[0m\u001B[01;34mazure\u001B[0m/          bank.csv  \u001B[01;34meventlogs\u001B[0m/                   \u001B[01;34mlogs\u001B[0m/\r\nbank-full.csv   bank.zip  \u001B[01;34mganglia\u001B[0m/                     \u001B[01;34mmetastore_db\u001B[0m/\r\nbank-names.txt  \u001B[01;34mconf\u001B[0m/     \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*  \u001B[01;32mpreload_class.lst\u001B[0m*\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0m\u001B[01;34mazure\u001B[0m/          bank.csv  \u001B[01;34meventlogs\u001B[0m/                   \u001B[01;34mlogs\u001B[0m/\r\nbank-full.csv   bank.zip  \u001B[01;34mganglia\u001B[0m/                     \u001B[01;34mmetastore_db\u001B[0m/\r\nbank-names.txt  \u001B[01;34mconf\u001B[0m/     \u001B[01;32mhadoop_accessed_config.lst\u001B[0m*  \u001B[01;32mpreload_class.lst\u001B[0m*\r\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Define the input and output formats and paths and the table name.\nwrite_format = 'delta'\nload_path = '/databricks/driver/bank.csv'\nsave_path = '/tmp/delta/bank-4k'\ntable_name = 'default.bank4k'\n\n# Load the data from its source.\ndf = spark.read.csv(\"file:/databricks/driver/bank.csv\")\n\n# Write the data to a table.\ndf.write.saveAsTable(table_name, path=\"file:/tmp/delta/bank-4k\")\n"],"metadata":{"id":"oeuoo24dKsvS","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf6ef357-8947-4766-a538-95cb6bdc6c7a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.rm(\"file:/tmp/delta/bank-4k\", True)  ## delete the table created in \"file:/tmp/delta/bank-4k\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4519e68-030e-4357-a6f6-8be2e2e651be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[24]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[24]: True"]}}],"execution_count":0},{"cell_type":"code","source":["# Write the data to a table\ndf.write.saveAsTable(table_name, path=\"file:/tmp/delta/bank-4k\")  ## saved as a parquet file. like csv but smaller \n\n## Milica's code \n# bank.write.format(write_format).save(save_path)\n# save_path = file:/databricks/driver/tmp/delta/bank-4k\n# bank.write.format(write_format).save(save_path)\n# or if there is a table already exists, run \n# bank.write.format(write_format).mode('overwrite').save(save_path)\n\n## Sina's code \n# df.write.csv(path=output_file_path, header=\"true\", mode=\"overwrite\", sep=‚Äú;‚Äù)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffbb9bee-fa6d-4317-8c59-87a7c6de939e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["1. Verify what we just created."],"metadata":{"id":"xSPA8U_WUr8s","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f261bded-5b52-479b-9c30-f370dab0a060"}}},{"cell_type":"code","source":["ls -lh /tmp/delta/bank-4k/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jqA0JktUqg8","outputId":"2dfea55f-a85f-4348-c55e-b1456e5b3cda","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0225e154-8644-4a73-bfc0-06883cb17d7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"total 64K\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 00:24 \u001B[0m\u001B[01;34m_delta_log\u001B[0m/\r\n-rw-r--r-- 1 root root  59K Sep 16 00:24 part-00000-a6a4fd8d-78ee-498a-b7aa-da86e7f587c2-c000.snappy.parquet\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["total 64K\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 00:24 \u001B[0m\u001B[01;34m_delta_log\u001B[0m/\r\n-rw-r--r-- 1 root root  59K Sep 16 00:24 part-00000-a6a4fd8d-78ee-498a-b7aa-da86e7f587c2-c000.snappy.parquet\r\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["1. Partition data by `job` status. \n\n  To speed up queries that have predicates involving the partition columns, we should partition data. Often time, we partition by anonymized user id; here we demonstrate the idea with `job`."],"metadata":{"id":"tz2noJLho8ME","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7ad6cfd-2774-4dc6-b72b-f1360fdbd808"}}},{"cell_type":"code","source":["import shutil\nshutil.rmtree(save_path) # To replace data, we need to remove the existing directory"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57515722-7d7c-4f65-b03d-e04702e8dd4f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["partition_by = 'job' # YOUR CODE HERE\nsave_path=\"file:/databricks/driver/tmp/delta/bank-4k/\"\n\n# Write the data to its target.\ndf.\\\n  write.\\\n  partitionBy(partition_by).\\\n  format(write_format). \\\n  save(save_path)"],"metadata":{"id":"hJCHS1OxnoUu","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57f2c399-cff4-4d9d-8491-c5f79dba61bf"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ls -lh ./tmp/delta/bank-4k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3N57HCGCoA6Y","outputId":"6e0e381f-4c10-4f1c-87f3-6edc442a6b08","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a15de77e-c47a-4d07-9abe-3e9dc110125c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"total 52K\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11  \u001B[0m\u001B[01;34m_delta_log\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=admin.'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=blue-collar'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=entrepreneur'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=housemaid'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=management'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=retired'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=self-employed'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=services'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=student'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=technician'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=unemployed'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=unknown'\u001B[0m/\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["total 52K\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11  \u001B[0m\u001B[01;34m_delta_log\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=admin.'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=blue-collar'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=entrepreneur'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=housemaid'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=management'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=retired'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=self-employed'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=services'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=student'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=technician'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=unemployed'\u001B[0m/\r\ndrwxr-xr-x 2 root root 4.0K Sep 16 01:11 \u001B[01;34m'job=unknown'\u001B[0m/\r\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["We only touch the surface of Delta Lake, for more information, check [Delta Lake guide](https://docs.databricks.com/delta/index.html)"],"metadata":{"id":"LFRWT4qobDCw","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf6370bb-3c06-4155-8102-7b70ae73d40c"}}},{"cell_type":"markdown","source":["## Part 2: Exploring The Data\n\nWe will use the direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict whether the client will subscribe (Yes/No) to a term deposit."],"metadata":{"id":"d6e3Lpd8606A","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e212db6-6e87-468b-abd7-15a720ff8b96"}}},{"cell_type":"markdown","source":["1. Load data from its source by specifying the data format and path; then check out the schemas."],"metadata":{"id":"ySKvPhY8ZOQx","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f3550d5-ee6d-4a2d-a043-c8838dc02175"}}},{"cell_type":"code","source":["read_format = 'delta'\nload_path = 'file:/tmp/delta/bank-4k/'\n\ndf = spark.read.format(read_format).load(load_path) \n\ndf.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVLwrGAN606A","outputId":"97781c0e-cea0-4476-a2b7-12e294da3113","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24bcf95a-d1ca-497c-9243-b0ab5556c6c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- age: string (nullable = true)\n |-- job: string (nullable = true)\n |-- marital: string (nullable = true)\n |-- education: string (nullable = true)\n |-- default: string (nullable = true)\n |-- balance: string (nullable = true)\n |-- housing: string (nullable = true)\n |-- loan: string (nullable = true)\n |-- contact: string (nullable = true)\n |-- day: string (nullable = true)\n |-- month: string (nullable = true)\n |-- duration: string (nullable = true)\n |-- campaign: string (nullable = true)\n |-- pdays: string (nullable = true)\n |-- previous: string (nullable = true)\n |-- poutcome: string (nullable = true)\n |-- y: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- age: string (nullable = true)\n |-- job: string (nullable = true)\n |-- marital: string (nullable = true)\n |-- education: string (nullable = true)\n |-- default: string (nullable = true)\n |-- balance: string (nullable = true)\n |-- housing: string (nullable = true)\n |-- loan: string (nullable = true)\n |-- contact: string (nullable = true)\n |-- day: string (nullable = true)\n |-- month: string (nullable = true)\n |-- duration: string (nullable = true)\n |-- campaign: string (nullable = true)\n |-- pdays: string (nullable = true)\n |-- previous: string (nullable = true)\n |-- poutcome: string (nullable = true)\n |-- y: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Here are the columns you should see:\n\n* Input variables: age, job, marital, education, default, balance, housing, loan, contact, day, month, duration, campaign, pdays, previous, poutcome\n\n* Output variable: y (deposit)\n\n2. Have a peek of the first five observations. Use the `.show()` method."],"metadata":{"id":"Aiqk3hQO606B","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08b5bb73-fc91-4240-a31c-036605467e8f"}}},{"cell_type":"code","source":["df.show(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWPoxTh7606B","outputId":"3287ef72-969f-463f-b922-46ed3d95dd46","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4adb46d8-b982-4928-819d-2f7cfd48d8f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n|age|        job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n|age|        job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["To get a prettier result, it can be nice to use Pandas to display our DataFrame. Use the Spark `.take()` method to get the first 5 rows and then convert to a pandas DataFrame. Don't forget to pass along the column names. You should see the same result as above, but in a more aesthetically appealing format."],"metadata":{"id":"mOITLLCvG4Sb","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ce59830-c3c7-4ce2-b340-8d4c339fc67c"}}},{"cell_type":"code","source":["import pandas as pd\npd.DataFrame(df.take(5), columns=df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"VRenwPrOGz0D","outputId":"3502ad2b-5d95-4f5c-b80c-e2e1fa68417b","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c214d77-c2e9-4eeb-9aad-fb9826d01f14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"metadata":{"kernelSessionId":"3b1aa1d9-e217d327a830fdb3dbc6728a"},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>unemployed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>1787</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>19</td>\n      <td>oct</td>\n      <td>79</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>4789</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>11</td>\n      <td>may</td>\n      <td>220</td>\n      <td>1</td>\n      <td>339</td>\n      <td>4</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1350</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>16</td>\n      <td>apr</td>\n      <td>185</td>\n      <td>1</td>\n      <td>330</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1476</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>3</td>\n      <td>jun</td>\n      <td>199</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>226</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>unemployed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>1787</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>19</td>\n      <td>oct</td>\n      <td>79</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>4789</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>11</td>\n      <td>may</td>\n      <td>220</td>\n      <td>1</td>\n      <td>339</td>\n      <td>4</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1350</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>16</td>\n      <td>apr</td>\n      <td>185</td>\n      <td>1</td>\n      <td>330</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1476</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>3</td>\n      <td>jun</td>\n      <td>199</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>226</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["3. We can also perform transformations on our DataFrame using the Pandas commands that we know and love using the [Pandas on Spark API](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html) **(new on Spark versions >= 3.2)**.  Pandas on Spark API was born out of the Databricks project, Koalas üê®, allows us to use the Pandas commands and aesthetically pleasing output that we know and love distributed on the speed and scale of Spark!  For a nice quickstart on Pandas on Spark, check out this [article](https://towardsdatascience.com/run-pandas-as-fast-as-spark-f5eefe780c45)!  Let's convert our Spark DataFrame to a Pandas on Spark DataFrame!"],"metadata":{"id":"1uKOs_Ka606B","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55e026ca-5791-47b0-94b2-619653306198"}}},{"cell_type":"code","source":["import pyspark.pandas as ps\n\npsdf = df.pandas_api()\npsdf.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"p7G6371u606C","outputId":"9a07865b-02c9-4c7f-a89e-c15b0265e6f4","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9abd6308-77f0-420b-a80a-03ef2928c963"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>unemployed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>1787</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>19</td>\n      <td>oct</td>\n      <td>79</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>4789</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>11</td>\n      <td>may</td>\n      <td>220</td>\n      <td>1</td>\n      <td>339</td>\n      <td>4</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1350</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>16</td>\n      <td>apr</td>\n      <td>185</td>\n      <td>1</td>\n      <td>330</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1476</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>3</td>\n      <td>jun</td>\n      <td>199</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>226</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>unemployed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>1787</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>19</td>\n      <td>oct</td>\n      <td>79</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>4789</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>11</td>\n      <td>may</td>\n      <td>220</td>\n      <td>1</td>\n      <td>339</td>\n      <td>4</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1350</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>16</td>\n      <td>apr</td>\n      <td>185</td>\n      <td>1</td>\n      <td>330</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>1476</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>3</td>\n      <td>jun</td>\n      <td>199</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>226</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["4. How many datapoints are there in the dataset? Use the `.count()` method."],"metadata":{"id":"UMK2KbvG606C","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79922c33-7974-4452-9c0e-c9c262391afb"}}},{"cell_type":"code","source":["psdf.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGCjBX-8606C","outputId":"dbf49fd1-5cb4-458c-c7f8-188dd8d9ecb0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2bccb04-2a21-4053-bac9-44db61d30a14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[43]: age          4521\njob          4521\nmarital      4521\neducation    4521\ndefault      4521\nbalance      4521\nhousing      4521\nloan         4521\ncontact      4521\nday          4521\nmonth        4521\nduration     4521\ncampaign     4521\npdays        4521\nprevious     4521\npoutcome     4521\ny            4521\ndtype: int64","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[43]: age          4521\njob          4521\nmarital      4521\neducation    4521\ndefault      4521\nbalance      4521\nhousing      4521\nloan         4521\ncontact      4521\nday          4521\nmonth        4521\nduration     4521\ncampaign     4521\npdays        4521\nprevious     4521\npoutcome     4521\ny            4521\ndtype: int64"]}}],"execution_count":0},{"cell_type":"markdown","source":["5. Use the `.describe()` method to see summary statistics on the features."],"metadata":{"id":"B6chyZha606D","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb7b30f2-d651-45e4-bdc8-6ded305c9485"}}},{"cell_type":"code","source":["psdf.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"mpmp504K606D","outputId":"97911142-6fb9-4ddc-f49c-363dfac124c4","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"277d7768-2f6d-4af0-afe6-61ca952adbb8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>67</td>\n      <td>12</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2353</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>31</td>\n      <td>12</td>\n      <td>875</td>\n      <td>32</td>\n      <td>292</td>\n      <td>24</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>34</td>\n      <td>management</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>20</td>\n      <td>may</td>\n      <td>123</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>231</td>\n      <td>969</td>\n      <td>2797</td>\n      <td>2306</td>\n      <td>4445</td>\n      <td>357</td>\n      <td>2559</td>\n      <td>3830</td>\n      <td>2896</td>\n      <td>257</td>\n      <td>1398</td>\n      <td>27</td>\n      <td>1734</td>\n      <td>3705</td>\n      <td>3705</td>\n      <td>3705</td>\n      <td>4000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n      <td>4521</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>67</td>\n      <td>12</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2353</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>31</td>\n      <td>12</td>\n      <td>875</td>\n      <td>32</td>\n      <td>292</td>\n      <td>24</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>34</td>\n      <td>management</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>20</td>\n      <td>may</td>\n      <td>123</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>231</td>\n      <td>969</td>\n      <td>2797</td>\n      <td>2306</td>\n      <td>4445</td>\n      <td>357</td>\n      <td>2559</td>\n      <td>3830</td>\n      <td>2896</td>\n      <td>257</td>\n      <td>1398</td>\n      <td>27</td>\n      <td>1734</td>\n      <td>3705</td>\n      <td>3705</td>\n      <td>3705</td>\n      <td>4000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["psdf.dtypes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a007ce9-c669-42a2-a72a-070988375ee2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[50]: age          object\njob          object\nmarital      object\neducation    object\ndefault      object\nbalance      object\nhousing      object\nloan         object\ncontact      object\nday          object\nmonth        object\nduration     object\ncampaign     object\npdays        object\nprevious     object\npoutcome     object\ny            object\ndtype: object","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[50]: age          object\njob          object\nmarital      object\neducation    object\ndefault      object\nbalance      object\nhousing      object\nloan         object\ncontact      object\nday          object\nmonth        object\nduration     object\ncampaign     object\npdays        object\nprevious     object\npoutcome     object\ny            object\ndtype: object"]}}],"execution_count":0},{"cell_type":"markdown","source":["6. The above result includes the columns that are categorical, so don't have useful summary statistics. Let's limit to just the numeric features.\n\n    `numeric_features` is defined below to contain the column names of the numeric features.  Notice we use the `zip` functions to iterate through two lists at the same time!\n    \n    Filter the DataFrame as you would in Pandas to select only the numeric features from the DataFrame and then get the summary statistics on the resulting DataFrame as we did above."],"metadata":{"id":"8hdB0-gZ606D","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7e85015-5739-4f67-bd73-af23d1decf4c"}}},{"cell_type":"code","source":["col_names = [name for name in psdf.dtypes.index]\ndtypes = [dtype for dtype in psdf.dtypes.tolist()]\n\nnumeric_features = [name for name, dtype in zip(col_names, dtypes) if dtype == 'int32']\nnumeric_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"xP4uY29z606E","outputId":"8fbfb144-ab13-41be-f43e-1137c256b5d8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b843ce9c-92bb-4e45-b54a-4fea20d7e5d7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O')]\nOut[52]: []","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O')]\nOut[52]: []"]}}],"execution_count":0},{"cell_type":"markdown","source":["7. Run the following code to look at correlation between the numeric features.  Let's convert our Pandas on Spark Datafrane to a Pandas DataFrame using the `to_pandas()` command so that we can plot.  What do you see?"],"metadata":{"id":"gOBPcOPe606E","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72534767-044a-417d-957c-ab26679b103d"}}},{"cell_type":"code","source":["# Convert Pandas on Spark DataFrame to Spark DataFrame\nnumeric_data = psdf[numeric_features].to_pandas()\n\naxs = pd.plotting.scatter_matrix(numeric_data, figsize=(8, 8));\nn = len(numeric_data.columns)\n\nfor i in range(n):\n    v = axs[i, 0]\n    v.yaxis.label.set_rotation(0)\n    v.yaxis.label.set_ha('right')\n    v.set_yticks(())\n    h = axs[n - 1, i]\n    h.xaxis.label.set_rotation(90)\n    h.set_xticks(())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"_3iYP4Ma606E","outputId":"f719637a-43b2-4817-99b1-3293e5875b4a","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1cfda4ef-8aa3-4f69-8ca8-101d11f17e8e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["There aren't any highly correlated variables, so we will keep them all for the model. It‚Äôs obvious that there aren‚Äôt highly correlated numeric variables. Therefore, we will keep all of them for the model. However, day and month columns are not really useful, so we will remove these two columns.\n\n8. Use the `.drop()` method to drop the `month` and `day` columns.\n    \n    Note that this method returns a new DataFrame, so save that result as `sdf`.\n\n    Use the `.dtypes` method to verify that `sdf` now has the correct columns."],"metadata":{"id":"oqJ0UpN7606E","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79d455fa-6ee2-4de6-b055-fece294607d9"}}},{"cell_type":"code","source":["# [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBiC1jtR606F","outputId":"22b40379-bf5e-47a0-b338-5e936d58109b","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"adef7a84-4270-4108-9849-ef699d0d7541"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 3: Preparing Data for Machine Learning\n\nWhat follows is something analagous to a dataloader pipeline in Tensorflow--we're going to chain together some transformations that will convert our categorical variables into a one-hot format more amenable to training a machine learning model. The next code cell just sets this all up, but it doesn't run these transformations on our data yet."],"metadata":{"id":"NaVpHgTy606F","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc7c7c08-3090-4609-b0b3-a5ffa6be0981"}}},{"cell_type":"markdown","source":["The process includes Category Indexing, One-Hot Encoding and VectorAssembler ‚Äî a feature transformer that merges multiple columns into a vector column."],"metadata":{"id":"gO45xEZ9606F","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72e6e744-d740-4365-b02a-cec38e4b0779"}}},{"cell_type":"markdown","source":["The code is taken from [databricks‚Äô official site](https://docs.databricks.com/applications/machine-learning/train-model/mllib/index.html#binary-classification-example) and it indexes each categorical column using the StringIndexer, then converts the indexed categories into one-hot encoded variables. The resulting output has the binary vectors appended to the end of each row. We use the StringIndexer again to encode our labels to label indices. Next, we use the VectorAssembler to combine all the feature columns into a single vector column."],"metadata":{"id":"TIBGTMSU606G","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c20c43bc-899c-46fd-8cd8-68f7faddd8b9"}}},{"cell_type":"markdown","source":["1. Complete the code by completing the assignment of `assembler`. Use `VectorAssembler` and pass in `assemblerInputs` as `inputCols` and name the `outputCol` `\"features\"`."],"metadata":{"id":"q5Zs_fki606G","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2688fb14-98cd-4da6-a856-3ee590d7030d"}}},{"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder , StringIndexer, VectorAssembler\n\ncategoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\nstages = []\n\nfor categoricalCol in categoricalColumns:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n    stages += [stringIndexer, encoder]\n\nlabel_stringIdx = StringIndexer(inputCol = 'y', outputCol = 'label')\nstages += [label_stringIdx]\nnumericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\nassemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\nassembler = None # [YOUR CODE HERE]\nstages += [assembler]"],"metadata":{"id":"beyBChtD606G","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f4b6f3b-a25b-4c93-ae7b-d9fcf8d451df"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 4: Pipeline"],"metadata":{"id":"gsTuJQBk606G","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a430a65-f90a-4941-8476-7497416dd0b8"}}},{"cell_type":"markdown","source":["We use Pipeline to chain multiple Transformers and Estimators together to specify our machine learning workflow. A Pipeline‚Äôs stages are specified as an ordered array.  So that we can run the pipeline on our Pandas on Spark DataFrame, we will convert it back to a Spark DataFrame using the **`to_spark()`** command\n\n1. Fit a pipeline on df."],"metadata":{"id":"mDNzrSSr606H","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6191ae8-826c-405c-835b-85ccde4ed00d"}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nsdf = psdf.to_spark()\npipeline = Pipeline(stages=stages)\n\npipelineModel = None # [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cUIirqy606H","outputId":"a661561f-45cb-4b65-fba0-f5e22db893d3","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30265e83-c80c-4144-a25b-b140b1fcc244"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["2. Transform `pipelineModel` on `df` and assign this to variable `transformed_df`."],"metadata":{"id":"FN6xXah5606H","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc50ea6e-fd7f-4e13-a53f-030c3ea9048a"}}},{"cell_type":"code","source":["transformed_df = None # [YOUR CODE HERE]\ntransformed_df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTsKIGt1606H","outputId":"d42b5902-4ac8-4e97-80ab-1d29f4753250","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f1ab6e0-b779-4085-a0ad-39b07396b6f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["From the transformation, we'd like to take the `label` and `features` columns as well as the original columns from `sdf.`\n\n3. Use the `.select()` method to pull these columns from the `transformed_df` and reassign the resulting DataFrame to `sdf`."],"metadata":{"id":"fS3OQX0p606H","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcca519d-f310-408c-93ff-aa058da26cd6"}}},{"cell_type":"code","source":["selectedCols = ['label', 'features'] + sdf.columns\nsdf = None # [YOUR CODE HERE]\nsdf.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWLr2mo0606I","outputId":"4ebeaf4d-f3f3-4a67-9480-93455b92cff3","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3916f079-5a8c-4504-a3ef-f255592f7ae8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["4. Let's view the first five rows of the `sdf` DataFrame using the methods we learned in Part 2:\n    * `.show()` method\n    * `.take()` method and convert result to a Pandas DataFrame"],"metadata":{"id":"rCA4o74C606I","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a85eb9e6-b5ac-45f0-8e01-438f49796df5"}}},{"cell_type":"code","source":["# [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":594},"id":"rUnHgPSY606I","outputId":"ad6b8ce7-5306-416e-cd30-4b5dad1acbbe","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b177c7ee-96a4-4340-952b-e02cb46faf25"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["5. Randomly split the dataset in training and test sets, with 70% of the data in the training set and the remaining 30% in the test set.\n\n    Hint: Call the `.randomSplit()` method."],"metadata":{"id":"NgtkTLyN606I","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"152186b5-5f8b-41ca-bd07-a9bf04310541"}}},{"cell_type":"code","source":["train, test = None # [YOUR CODE HERE]"],"metadata":{"id":"pOV9t-nj606I","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4798af7-e77f-4ebb-891f-c814799f8618"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["6. What are the sizes of the training and test sets?"],"metadata":{"id":"ch88ygkE606J","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c6f5db8-46cd-4f56-82c9-881becc28d14"}}},{"cell_type":"code","source":["# [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYQ9e6Ha606J","outputId":"2d73d0d2-decb-42de-e7ec-813bc2f1caf2","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddca24d1-be11-4257-b3c9-0de7c97e8d06"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 5: Logistic Regression Model\n\n- You can build a RandomForestClassifier with : from pyspark.ml.classification import RandomForestClassifier\n- You can build a Gradient-Boosted Tree Classifier with : from pyspark.ml.classification import GBTClassifier\n\n1. Fit a LogisticRegression with `featuresCol` as `\"features\"`, `labelCol` as `\"label\"` and a `maxIter` of 10."],"metadata":{"id":"IWNVbqgU606J","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42af67c4-7257-40f0-8219-069494123190"}}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# [YOUR CODE HERE]"],"metadata":{"id":"7StSP1Jv606J","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45df93be-c36f-4b6c-8393-13e39311e218"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["2. We can obtain the coefficients by using LogisticRegressionModel‚Äôs attributes. Look at the following plot of the beta coefficients."],"metadata":{"id":"OMSgeFA1606J","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb297027-929c-4637-8ed2-64bff31e1fd4"}}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\nbeta = np.sort(lrModel.coefficients)\nplt.plot(beta)\nplt.ylabel('Beta Coefficients')\nplt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"bh28ROSu606J","outputId":"c208b6b6-2be5-4fbf-ec7b-c6e387a4fd12","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1766292-117f-4ea2-89fe-2c62612a600b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["3. Use the `.transform()` method to make predictions and save them as `predictions`."],"metadata":{"id":"K3hE2Ja2606K","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a850fb0a-0d4d-4f58-8c23-2aea0db2f3f1"}}},{"cell_type":"code","source":["predictions = None # [YOUR CODE HERE]"],"metadata":{"id":"9X_xoxnF606K","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdf395d5-b7ef-4f5a-8a32-f1eb76b59122"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["4. View the first 10 rows of the `predictions` DataFrame."],"metadata":{"id":"NIXVUZLv606K","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddccadb9-961e-448e-b193-dc1930c35be1"}}},{"cell_type":"code","source":["# [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1AD_mkwl606K","outputId":"0024428e-6085-4f88-80d4-629d3e0c8130","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b9465f1-1159-436e-a882-9d1a5325ab33"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["5. What is the area under the curve?\n\n    You can find it with the `evaluator.evaluate()` function."],"metadata":{"id":"Z-2MVhsn606K","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d61bb1a-4a0f-4670-b9c6-b08b10607ee4"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\n# [YOUR CODE HERE]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bH62bSe606K","outputId":"eb427a7f-ac11-4e3b-dc59-8f96ca0bc602","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5308cabd-37c2-43d2-bb24-19d638ec54e9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## OPTIONAL: HyperParameter Tuning a Gradient-Boosted Tree Classifier\n\n1. Fit and make predictions using `GBTClassifier`. The syntax will match what we did above with `LogisticRegression`."],"metadata":{"id":"iL4_IuwT606L","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a5ca7ac-9dd1-4610-93c2-41a53c40da74"}}},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(maxIter=10)\ngbtModel = gbt.fit(train)\npredictions = gbtModel.transform(test)\npredictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROwTeFaz606L","outputId":"e4823b97-3e5c-4a18-fb62-4d46e5c31c97","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e207bd8b-47a0-435a-8e82-affae0da0b9c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["2. Run some cross validation to compare different parameters.\n\n    Note that it can take a while because it's training over many gradient boosted trees. Give it at least 10 minutes to complete."],"metadata":{"id":"5Od9M0JV606L","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eafee88c-db02-4818-ae96-6165bd61ca1a"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid = (ParamGridBuilder()\n             .addGrid(gbt.maxDepth, [2, 4, 6])\n             .addGrid(gbt.maxBins, [20, 60])\n             .addGrid(gbt.maxIter, [10, 20])\n             .build())\ncv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\ncvModel = cv.fit(train)\npredictions = cvModel.transform(test)\nevaluator.evaluate(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Upc0CJf606L","outputId":"62d9aae2-ed37-491d-b651-1c5ec81d8e2e","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e9fcb9e-a99a-41fa-bc9f-e58a5f5513bb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Acknowledgements"],"metadata":{"id":"psf7A_uz606M","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac06b1cb-a339-4990-ad01-73e76511d072"}}},{"cell_type":"markdown","source":["This notebook is adapted from [Machine Learning with PySpark and MLlib](https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa)"],"metadata":{"id":"HH1MXhRU606M","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f88d237-4c62-4af2-90de-d4fedce788e6"}}}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.9.12","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"subscription-prediction","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2939291325575199},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"toc":{"title_sidebar":"Contents","nav_menu":{},"sideBar":true,"number_sections":true,"skip_h1_title":false,"base_numbering":1,"toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false,"title_cell":"Table of Contents"}},"nbformat":4,"nbformat_minor":0}
