{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Machine Learning Engineering Onramp</h1>\n",
    "# <h2 align=\"center\" id=\"heading\">MLE Basic Toolkit üß∞</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn the basics of some of the most widely used libraries in Python for Machine Learning:\n",
    "* `pandas` - for data manipulation and exploratory data analysis,\n",
    "* `scikit-learn` aka `sklearn` - for predictive data analysis and machine learning\n",
    "* `matplotlib` and `seaborn` - for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas üêº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas](https://pandas.pydata.org/) is a powerful, versatile and easy-to-use tool for data mannipulation and data analysis and is the ML Engineer's Swiss Army knife for tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start off by creating a DataFrame from scratch!\n",
    "\n",
    "A `DataFrame` is a data structure that is used to organize data into a 2-dimensional table of rows and columns.  You can think of a DataFrame as a spreadsheet or SQL table.\n",
    "\n",
    "First we'll import `pandas` using the conventional abbreviation `pd`, which will not only save us some keystrokes, but also make our code less verbose.  While we can abbreviate any package with any notation, it is best to follow the conventions set by the authors of the package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a DataFrame using the following steps:\n",
    "1. Create a couple of lists\n",
    "2. Create a dictionary mapping for those lists\n",
    "3. Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     names  nums\n",
      "0     Greg     1\n",
      "1     Sina     2\n",
      "2   Milica     3\n",
      "3    Chris     4\n",
      "4  Michael     5\n"
     ]
    }
   ],
   "source": [
    "names = [\"Greg\", \"Sina\", \"Milica\", \"Chris\", \"Michael\"]\n",
    "nums = [1, 2, 3, 4, 5]\n",
    "\n",
    "data = {\"names\":names, \"nums\":nums}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily add data by creating new rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     names  nums            roles\n",
      "0     Greg     1  Head of Product\n",
      "1     Sina     2       Instructor\n",
      "2   Milica     3       Instructor\n",
      "3    Chris     4       Instructor\n",
      "4  Michael     5       Instructor\n",
      "5      Ali     6       Instructor\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for roles\n",
    "roles = [\"Head of Product\", \"Instructor\", \"Instructor\", \"Instructor\", \"Instructor\"]\n",
    "df[\"roles\"] = roles\n",
    "\n",
    "# Append a new row using a list\n",
    "df.loc[len(df)] = [\"Ali\", 6, \"Instructor\"] \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     names  nums            roles\n",
      "0     Greg     1  Head of Product\n",
      "1     Sina     2       Instructor\n",
      "2   Milica     3       Instructor\n",
      "3    Chris     4       Instructor\n",
      "4  Michael     5       Instructor\n",
      "5      Ali     6       Instructor\n",
      "6    Bruno     7       Instructor\n"
     ]
    }
   ],
   "source": [
    "# Append a new row using a pd.Series\n",
    "# new = [\"Bruno\", 7, \"Instructor\"]\n",
    "# df = df.append(pd.Series(new, index=df.columns[:len(new)]), ignore_index=True)\n",
    "\n",
    "# Append a new row using pd.concat \n",
    "new_row = pd.DataFrame({\"names\": \"Bruno\", \"nums\": 7, \"roles\": \"Instructor\"}, index=[0])\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we specify an index that already exists in the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>nums</th>\n",
       "      <th>roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greg</td>\n",
       "      <td>1</td>\n",
       "      <td>Head of Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sina</td>\n",
       "      <td>2</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milica</td>\n",
       "      <td>3</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris</td>\n",
       "      <td>4</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael</td>\n",
       "      <td>5</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ali</td>\n",
       "      <td>6</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Milan</td>\n",
       "      <td>8</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     names  nums            roles\n",
       "0     Greg     1  Head of Product\n",
       "1     Sina     2       Instructor\n",
       "2   Milica     3       Instructor\n",
       "3    Chris     4       Instructor\n",
       "4  Michael     5       Instructor\n",
       "5      Ali     6       Instructor\n",
       "6    Milan     8       Instructor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[6] = [\"Milan\", 8, \"Instructor\"] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops, we have overwritten Bruno!  Let's add him back, but this time let's use an insert.  There isn't a great way to do this in Pandas, but we can also use `numpy` to help us out with this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Greg' 1 'Head of Product']\n",
      " ['Sina' 2 'Instructor']\n",
      " ['Milica' 3 'Instructor']\n",
      " ['Chris' 4 'Instructor']\n",
      " ['Michael' 5 'Instructor']\n",
      " ['Ali' 6 'Instructor']\n",
      " ['Milan' 8 'Instructor']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>nums</th>\n",
       "      <th>roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greg</td>\n",
       "      <td>1</td>\n",
       "      <td>Head of Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sina</td>\n",
       "      <td>2</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milica</td>\n",
       "      <td>3</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris</td>\n",
       "      <td>4</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael</td>\n",
       "      <td>5</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ali</td>\n",
       "      <td>6</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bruno</td>\n",
       "      <td>7</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Milan</td>\n",
       "      <td>8</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     names nums            roles\n",
       "0     Greg    1  Head of Product\n",
       "1     Sina    2       Instructor\n",
       "2   Milica    3       Instructor\n",
       "3    Chris    4       Instructor\n",
       "4  Michael    5       Instructor\n",
       "5      Ali    6       Instructor\n",
       "6    Bruno    7       Instructor\n",
       "7    Milan    8       Instructor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(df.values)\n",
    "df = pd.DataFrame(np.insert(df.values, 6, values=[\"Bruno\", 7, \"Instructor\"], axis=0), columns=df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving Deeper ü§ø \n",
    "Now that we can create our own DataFrame from scratch, let's take another dataset and clean it up and analyze it!  We will load the [diabetes dataset](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html) that comes in pre-loaded in `sklearn`.  `Sklearn` comes preloaded with several [datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html) and are great for practicing data exploration and ML techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_diabetes\n\u001b[1;32m      2\u001b[0m dfX, Y \u001b[38;5;241m=\u001b[39m load_diabetes(return_X_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, as_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m dfX\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "dfX, Y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "dfX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we are given 10 variables of interest to predict diabetes progression after one year.  Notice that columns 5-10 are not given meaningful names, let's rename this columns using a dictionary mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\"s1\":\"tc\", \"s2\":\"ldl\", \"s3\":\"hdl\", \"s4\":\"tch\", \"s5\":\"ltg\", \"s6\":\"glu\"}\n",
    "dfX = dfX.rename(columns=cols)\n",
    "dfX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though, our X values are returned to us as a DataFrame, our Y values are returned as a Pandas series ([pd.series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)).  Let's create a DataFrame for it as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.DataFrame({\"disease_progression\": Y})\n",
    "dfY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis üó∫Ô∏è üß≠ ‚õèÔ∏è\n",
    "Now let's begin exploring the data!  We can call the `shape` function in Pandas to learn the dimensions our DataFrames.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our DataFrames contain 442 rows and 10 columns.  Let's make sure that our `dfY` DataFrame.  Give a try in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our DataFrames are the same length, let's add the dependent variable (Y) DataFrame to our DataFrame with our independent variables (X).  \n",
    "\n",
    "We can also use the `head` function to return the first rows of the DataFrame.  This allows us to peek üëÄ the data, rather than return the whole DataFrame which can be helpful for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX[\"disease_prog\"] = dfY\n",
    "dfX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we have any null values that we need to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like we have any nulls to deal with.  Let's use the `describe` function to give us some descriptive statistics about the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualize the Data\n",
    "\n",
    "Let's visualize the data with the help of [matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/) libraries.  `Matplotlib` is a comprehensize data visualization library and can be used for customized static, as well as dynamic and interactive plots.  `Seaborn` is a high-level library for common statistical visualizations that runs `matplotlib` under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.displot(dfX[\"disease_prog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a look at the correlations among our variables using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dfX.corr()\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.heatmap(dfX.corr(), annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since half of the data in the heatmap above is redundant, we can mask the upper triangle using a mask, which gives us a cleaner, less busy, correlogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "mask = np.triu(np.ones_like(dfX.corr()))\n",
    "sns.heatmap(dfX.corr(), mask=mask, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a moderate correlation between `disease_prog` and `ltg` (0.57) and `bmi` (0.59).  It is also worth noting that there is a strong correlation between `ldl` and `tc` (0.9).\n",
    "\n",
    "Let's see if we can note any relationship between these variables by looking at some pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#plotting graphs\n",
    "sns.pairplot(dfX[[\"bmi\", \"ltg\", \"disease_prog\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationships above look approximately linear.  We can also plot a regression plot to evaluate the linear relationship a more closely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#regression between bmi and progression\n",
    "sns.regplot(data=dfX, x=\"bmi\", y=\"disease_prog\",line_kws={\"color\": \"red\"})\n",
    "\n",
    "#labeling\n",
    "plt.title(\"BMI VS Disease Progression\")\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Disease Progression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#regression between bmi and progression\n",
    "sns.regplot(data=dfX, x=\"ltg\", y=\"disease_prog\",line_kws={\"color\": \"red\"})\n",
    "\n",
    "#labeling\n",
    "plt.title(\"LTG VS Disease Progression\")\n",
    "plt.xlabel(\"LTG\")\n",
    "plt.ylabel(\"Disease Progression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there does appear to be a linear relationship between both `bmi` and `ltg` and `disease_prog`, there is a lot of dispersion as well, but this also make sense since we only had a moderate correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop our Y value, `disease_prog`, from the DataFrame so that we can perform a regression analysis using sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfX.drop([\"disease_prog\"], axis=1)\n",
    "dfX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data ‚ûó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our dataset into `train` and `test` datasets - this will allow our model to learn from the `train` data and we can evaluate the performance of the model on the `test` data that it hasn't seen before.  Since this is a small dataset, we will use 90% of the data for training and 10% for testing.  We will also set a `random_state` for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(dfX, dfY, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions üîÆ \n",
    "\n",
    "Now we can fit the data to the model by calling the `fit` (dot-fit) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "y_train_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model üìè "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model with the data, make some predictions and evaluate our model using the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) (R^2 aka R-squared).  This will tell us how much of the variance of the data can be explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intercept\n",
    "print(f\"the intercept is:{lr.intercept_[0]: .2f}\")\n",
    "\n",
    "#slopes\n",
    "print(f\"the slopes are:{lr.coef_}\")\n",
    "\n",
    "#Score model using R^2\n",
    "print(f\"R2 on train set:{lr.score(X_train, y_train): .2f}\") #train set\n",
    "print(f\"R2 on test set:{lr.score(X_test, y_test): .2f}\") #test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 is only around 0.5, which demonstrates a moderate fit. While this might seem low, it can be perfectly acceptable in some cases. This result is not totally unexpected as we only had moderate correlations between our independent and dependent variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions üßë‚Äçüè´ \n",
    "\n",
    "In this exercise, we went through many of the basic functions of `pandas`, performed an exploratory data analysis (EDA), made data visualizations using `matplotlib` and `seaborn` and went through the ML worflow in `sklearn`.  Now that we have covered many of the basics of some of the core packages that we will be using in this course, you've got a firm foundation to build on!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f70fe2e7e7cb52bf2bf0a2d8cc8af5768efe1556307d7c8f07dd0e6b20b16428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
